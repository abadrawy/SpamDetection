{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from nltk import pos_tag,word_tokenize,sent_tokenize\n",
    "import pyphen\n",
    "import enchant\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2893\n",
      "2893\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "for fname in glob.glob('data/lingspam_public/bare/*/*'):\n",
    "    with open(fname,encoding='utf-8') as f:\n",
    "        data.append('\\n'.join(f.readlines()))\n",
    "        if(\"spm\" in fname):\n",
    "            labels.append(1)#spam\n",
    "        else:\n",
    "            labels.append(0) #notspam\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2314, 53930)\n"
     ]
    }
   ],
   "source": [
    "#using a simple count vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train=vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(clf,X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print('Precision  : ',metrics.precision_score(y_test, y_pred, average='macro'))\n",
    "    print('Recall  : ',metrics.recall_score(y_test, y_pred, average='macro'))\n",
    "    print('F1_score  : ',metrics.f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Precision  :  0.987223148369\n",
      "Recall  :  0.992027417027\n",
      "F1_score  :  0.989607576836\n"
     ]
    }
   ],
   "source": [
    "#MultinomialNB with countVectorizer\n",
    "clf= MultinomialNB()\n",
    "print(\"MultinomialNB\")\n",
    "classify(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means\n",
      "Precision  :  0.952777777778\n",
      "Recall  :  0.911616161616\n",
      "F1_score  :  0.930742062818\n"
     ]
    }
   ],
   "source": [
    "#K-means neigbout with countVecotrizer\n",
    "clf=KNeighborsClassifier(n_neighbors=3)\n",
    "print(\"K-means\")\n",
    "classify(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Precision  :  0.952777777778\n",
      "Recall  :  0.911616161616\n",
      "F1_score  :  0.930742062818\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with countVectorizer\n",
    "clf_RF=RandomForestClassifier(n_estimators=10,random_state=0)\n",
    "print(\"Random Forest\")\n",
    "classify(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features_extraction(email):\n",
    "    dic={\n",
    "        'F1':len(sent_tokenize(email)),\n",
    "        'F2':number_verbs(word_tokenize(email)),\n",
    "        'F3':hasNumbers(word_tokenize(email)),\n",
    "        'F4':in_spam_list(word_tokenize(email)),\n",
    "        'F5':num_words_syl(word_tokenize(email))[0],\n",
    "        'F6':num_words_syl(word_tokenize(email))[1],\n",
    "        #'F7':num_misspelled(word_tokenize(email)),\n",
    "        'F9':sum_tfidf([email])\n",
    "                             }\n",
    "    return dic;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def number_verbs(email):\n",
    "    tagged=[]\n",
    "    tagged+=pos_tag(email)\n",
    "    return (len(set([word for (word, tag) in tagged if 'VB' in tag[:2] ])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hasNumbers(email):\n",
    "    hasD=False;\n",
    "    hasA=False;\n",
    "    count=0\n",
    "    for word in email:\n",
    "            for char in word:\n",
    "                if(char.isdigit()):\n",
    "                    hasD=True\n",
    "                if(char.isalpha()):\n",
    "                    hasA=True\n",
    "            if(hasD and hasA):\n",
    "                count+=1\n",
    "            hasD=False\n",
    "            hasA=False\n",
    "    return count\n",
    "                \n",
    "     \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def in_spam_list(email):\n",
    "    count=0\n",
    "    with open('data/spamlist.txt',encoding='latin-1') as f:\n",
    "        spamlist=f.readlines()\n",
    "    for word in email:\n",
    "        if word in spamlist:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_syl(word):\n",
    "    dic = pyphen.Pyphen(lang='en_GB')\n",
    "    syl=dic.inserted(word)\n",
    "    return len(syl.split('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_words_syl(email):\n",
    "    count_3=0\n",
    "    avg=0\n",
    "    for word in email:\n",
    "        if(num_syl(word)>3):\n",
    "            count_3+=1\n",
    "            avg+=num_syl(word)\n",
    "    return (count_3, avg/len((email)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_misspelled(email):\n",
    "    count=0\n",
    "    d = enchant.Dict('en_GB')\n",
    "    for word in email:\n",
    "        if(not d.check(word)):\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_tfidf(email):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf=vectorizer.fit_transform(email).toarray()\n",
    "    return np.sum(tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#apply feature extraction on the data\n",
    "fe_data=[]\n",
    "for email in data:\n",
    "    fe_data.append(features_extraction(email))\n",
    "\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(fe_data, labels, test_size=0.2, random_state=101)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transfomr list of dic to list of list\n",
    "vec = DictVectorizer()\n",
    "X_train= vec.fit_transform(X_train)\n",
    "X_test= vec.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Precision  :  0.69189569143\n",
      "Recall  :  0.733080808081\n",
      "F1_score  :  0.70845763602\n"
     ]
    }
   ],
   "source": [
    "#MultinomialNB with feature extraction\n",
    "clf= MultinomialNB()\n",
    "print(\"MultinomialNB\")\n",
    "classify(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means\n",
      "Precision  :  0.738331799231\n",
      "Recall  :  0.711724386724\n",
      "F1_score  :  0.723683959353\n"
     ]
    }
   ],
   "source": [
    "#K-means neigbout with feature extraction\n",
    "clf=KNeighborsClassifier(n_neighbors=3)\n",
    "print(\"K-means\")\n",
    "classify(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Precision  :  0.780027453672\n",
      "Recall  :  0.715873015873\n",
      "F1_score  :  0.741363907088\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with feature extraction\n",
    "clf=RandomForestClassifier(n_estimators=10,random_state=0)\n",
    "print(\"Random Forest\")\n",
    "classify(clf, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
